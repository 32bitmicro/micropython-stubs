{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get/Update Download statistics\n",
    "\n",
    "This Jupyter Notebook contains code and analysis for analyzing and visualizing data from the PyPI package repository. The notebook utilizes the Google BigQuery API to query and retrieve data, and pandas and matplotlib libraries for data manipulation and visualization.\n",
    "\n",
    "The notebook is divided into several sections, each represented by a separate code cell. The sections include:\n",
    "\n",
    "1. Data Retrieval: This section retrieves monthly download statistics for a specific package from the PyPI repository using the BigQuery API.\n",
    "\n",
    "2. Data Processing: This section processes and combines the retrieved data with the existing data from a CSV file. It performs data cleaning, sorting, and removes duplicate entries.\n",
    "\n",
    "3. Data Visualization: This section visualizes the processed data using various charts and plots, including bar charts and line plots.\n",
    "\n",
    "4. Data Export: This section exports the processed data to a CSV file for further analysis or sharing.\n",
    "\n",
    "#### Dependencies\n",
    "Please note that this notebook requires the installation of the necessary dependencies, such as pandas, matplotlib, and the Google Big Query SDK.\n",
    "\n",
    "see [requirements-stats.txt](../requirements-stats.txt) for a list of dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create service account from BQ_CREDS file\n",
    "credentials = service_account.Credentials.from_service_account_file(\"..\\.secrets_\\BQ_CREDS.json\")\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monthly_stats(year, month):\n",
    "    QUERY = f\"\"\"\n",
    "        SELECT\n",
    "          COUNT(*) AS downloads,\n",
    "          REGEXP_EXTRACT(file.project, r\".*?-(.*?)-(?:.*-)?stubs\") AS port,\n",
    "          REGEXP_EXTRACT(file.project, r\".*?-.*?-(?:(.*)-)?stubs\") AS board,\n",
    "          REGEXP_EXTRACT(file.version, r\"(.*).post\") AS version,\n",
    "          DATE({year},{month},1) as report_date,\n",
    "          file.project as project,\n",
    "          file.version AS version_full,\n",
    "          -- REGEXP_EXTRACT(file.version, r\".*.post(.*)\") AS post,\n",
    "        FROM\n",
    "          `bigquery-public-data.pypi.file_downloads`\n",
    "        WHERE\n",
    "          file.PROJECT LIKE 'micropython-%-stubs' -- Only query the previous month OF history\n",
    "          AND DATE(timestamp) BETWEEN DATE({year},{month},1)\n",
    "          AND DATE_ADD(DATE({year},{month},1), INTERVAL 1 MONTH)\n",
    "          AND details.installer.name <> 'bandersnatch'\n",
    "        GROUP BY\n",
    "          port,\n",
    "          board,\n",
    "          version,\n",
    "          project,\n",
    "          version_full\n",
    "          -- ,post\n",
    "        ORDER BY\n",
    "          `downloads` DESC\n",
    "        \"\"\"\n",
    "    query_job = client.query(QUERY)  # API request\n",
    "\n",
    "    results = query_job.result()  # Waits for query to finish\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "stats_list = []\n",
    "\n",
    "year = 2023\n",
    "\n",
    "# get the current year and month\n",
    "year = datetime.datetime.now().year\n",
    "this_month = datetime.datetime.now().month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last date in current data: 2023-10-01\n",
      "Last month: 10, last year: 2023\n"
     ]
    }
   ],
   "source": [
    "# read the current data from the csv file\n",
    "csv_file = Path(\".\") / \"downloads.csv\"\n",
    "with open(csv_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    current_stats_list = [row for row in reader]\n",
    "\n",
    "# sort the current stats list by date and get the latest date\n",
    "current_stats_list.sort(key=lambda x: x[\"report_date\"])\n",
    "last_date = current_stats_list[-1][\"report_date\"]\n",
    "print(f\"Last date in current data: {last_date}\")\n",
    "\n",
    "# get the month and year of the last date\n",
    "last_month = int(last_date.split(\"-\")[1])\n",
    "last_year = int(last_date.split(\"-\")[0])\n",
    "\n",
    "print (f\"Last month: {last_month}, last year: {last_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2023-10 ... Retrieved 107 download summaries\n",
      "Processing 2023-11 ... Retrieved 49 download summaries\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for month in range(last_month, this_month+1):\n",
    "    print(f\"Processing {year}-{month} ... \", end=\"\", flush=True)\n",
    "    results = get_monthly_stats(year, month)\n",
    "    field_names = [f.name for f in results.schema]\n",
    "    # print(field_names)\n",
    "    print(f\"Retrieved {results.total_rows} download summaries\")\n",
    "    for row in results:\n",
    "        stats_list.append(dict(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = current_stats_list + stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid double counts \n",
    "unique = {}\n",
    "for rec in full_list:\n",
    "    key = f\"{rec['report_date']}-{rec['project']}-{rec['version_full']}\"\n",
    "    unique[key] = rec\n",
    "\n",
    "full_list = list(unique.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to csv\n"
     ]
    }
   ],
   "source": [
    "print(\"writing to csv\")\n",
    "keys = full_list[0].keys()\n",
    "\n",
    "with open(csv_file, \"w\", newline=\"\") as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "\n",
    "    dict_writer.writerows(full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
